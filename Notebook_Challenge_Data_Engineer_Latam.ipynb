{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Data Engineer LATAM - Juan Felipe Hurtado\n",
    "\n",
    "- El archivo json se tiene en el directorio raiz de este archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importaciones globales del reto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ujson as json\n",
    "import emoji\n",
    "import re\n",
    "import cProfile\n",
    "import pstats\n",
    "from memory_profiler import profile\n",
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Las top 10 fechas donde hay más tweets. \n",
    "Mencionar el usuario (username) que más publicaciones tiene por cada uno de esos días.\n",
    "- Enfoque: Tiempo de ejecucion optimizado.\n",
    "\n",
    "- Descripción:\n",
    "Este código define una función llamada q1_time que procesa un archivo. Si existe un archivo Parquet más reciente que el archivo original, lo lee; de lo contrario, lee el archivo JSON, realiza manipulaciones de datos y lo guarda como Parquet. Luego, identifica las 10 fechas con más apariciones en el archivo original y, para cada una de ellas, encuentra el nombre de usuario con más apariciones en esa fecha. El resultado final es una lista de tuplas que contienen la fecha y el nombre de usuario correspondiente para las 10 fechas principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_time(archivo_json: str) -> List[Tuple[datetime.date, str]]:\n",
    "    # Separar el nombre del archivo y su extensión\n",
    "    nombre_archivo, _ = os.path.splitext(archivo_json)\n",
    "    archivo_parquet = f\"{nombre_archivo}.parquet\"\n",
    "    \n",
    "    # Verificar si existe un archivo parquet más reciente que el JSON\n",
    "    if os.path.exists(archivo_parquet) and os.path.getmtime(archivo_parquet) >= os.path.getmtime(archivo_json):\n",
    "        # Si existe y es más reciente, cargar datos desde el archivo parquet\n",
    "        df = pd.read_parquet(archivo_parquet)\n",
    "    else:\n",
    "        # Si no existe un archivo parquet o es más antiguo, cargar datos desde el JSON\n",
    "        df = pd.read_json(archivo_json, lines=True)\n",
    "        # Optimizar la conversión de fecha y extracción de nombre de usuario\n",
    "        df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "        df['username'] = df['user'].apply(lambda x: x.get('username'))\n",
    "        df.drop(columns=['user'], inplace=True)\n",
    "        # Guardar los datos procesados en formato parquet\n",
    "        df.to_parquet(archivo_parquet, index=False)\n",
    "\n",
    "    # Obtener el usuario con más tweets para cada fecha de manera eficiente\n",
    "    top_users_df = df.groupby(['date', 'username']).size().reset_index(name='count')\n",
    "    top_users_df = top_users_df.loc[top_users_df.groupby('date')['count'].idxmax()]\n",
    "    \n",
    "    # Encontrar las 10 fechas con más tweets y los usuarios correspondientes de manera eficiente\n",
    "    top_dates_df = df['date'].value_counts().nlargest(10).reset_index()\n",
    "    result = [(fecha, top_users_df[top_users_df['date'] == fecha]['username'].values[0]) for fecha in top_dates_df['index']]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Enfoque: Memoria en uso optimizada\n",
    " - Descripción: Este código define una función llamada q1_memory que procesa un archivo de texto. Lee cada línea del archivo, interpreta cada línea como un objeto JSON que representa un tweet, y realiza un seguimiento de la fecha y el nombre de usuario más frecuentes para cada fecha. Luego, encuentra las 10 fechas con mayor número de usuarios únicos y devuelve una lista de tuplas que contienen la fecha y el nombre de usuario más frecuente para cada una de esas fechas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    # Crear un diccionario anidado para contar usuarios por fecha\n",
    "    usuarios_por_fecha = defaultdict(lambda: defaultdict(int))\n",
    "    # Abrir el archivo en modo lectura\n",
    "    with open(file_path, \"r\") as archivo:\n",
    "        # Iterar sobre cada línea en el archivo\n",
    "        for linea in archivo:\n",
    "            # Cargar cada línea como un objeto JSON\n",
    "            tweet = json.loads(linea)\n",
    "            # Extraer la fecha del tweet y convertirla en un objeto de fecha\n",
    "            fecha_tweet_str = tweet['date'].split(\"T\")[0]\n",
    "            fecha_tweet = datetime.strptime(fecha_tweet_str, '%Y-%m-%d').date()\n",
    "            # Obtener el nombre de usuario del tweet\n",
    "            nombre_usuario = tweet['user']['username']\n",
    "            # Actualizar el contador de usuarios por fecha\n",
    "            usuarios_por_fecha[fecha_tweet][nombre_usuario] += 1\n",
    "    # Inicializar una lista vacía para almacenar las fechas y usuarios principales\n",
    "    fechas_usuarios_principales = []\n",
    "    # Iterar a través de las fechas y sus recuentos de usuarios\n",
    "    for fecha, recuentos_usuarios in usuarios_por_fecha.items():\n",
    "        # Encontrar el usuario con el recuento máximo para cada fecha\n",
    "        usuario_principal = max(recuentos_usuarios, key=recuentos_usuarios.get)\n",
    "        # Agregar la fecha y el usuario principal a la lista\n",
    "        fechas_usuarios_principales.append((fecha, usuario_principal))\n",
    "    # Ordenar la lista por recuento de usuarios en orden descendente y tomar las 10 primeras entradas\n",
    "    resultado = sorted(fechas_usuarios_principales, key=lambda x: usuarios_por_fecha[x[0]][x[1]], reverse=True)[:10]\n",
    "\n",
    "    return resultado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Los top 10 emojis más usados con su respectivo conteo.\n",
    "- Enfoque: Tiempo de ejecucion optimizado\n",
    "- Descripción: Este código define una función llamada q2_time que procesa un archivo. Primero, verifica si existe un archivo Parquet con el mismo nombre que el archivo JSON de entrada. Si existe, lo lee; de lo contrario, lee el archivo JSON, extrae los emojis de los contenidos de los tweets, cuenta la frecuencia de cada emoji y devuelve una lista de los 10 emojis más comunes junto con sus recuentos. El resultado final es una lista de tuplas que contienen el emoji y su frecuencia de aparición en los tweets del archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Crea el nombre del archivo Parquet reemplazando la extensión .json por .parquet\n",
    "    archivo_parquet = file_path.replace('.json', '.parquet')\n",
    "    \n",
    "    # Verifica si existe el archivo Parquet\n",
    "    if os.path.exists(archivo_parquet):\n",
    "        # Lee el archivo Parquet si existe\n",
    "        df = pd.read_parquet(archivo_parquet)\n",
    "    else:\n",
    "        # Lee el archivo JSON si el Parquet no existe y lo guarda como Parquet\n",
    "        df = pd.read_json(file_path, lines=True)\n",
    "        df.to_parquet(archivo_parquet, index=False)\n",
    "    \n",
    "    # Inicializa una lista vacía para almacenar todos los emojis en el contenido de los tweets\n",
    "    todos_emojis = []\n",
    "    \n",
    "    # Itera a través de la columna 'content' del DataFrame\n",
    "    for contenido in df['content']:\n",
    "        # Extrae los emojis de cada contenido y los agrega a la lista de todos los emojis\n",
    "        emojis_en_contenido = [entrada['emoji'] for entrada in emoji.emoji_list(contenido)]\n",
    "        todos_emojis.extend(emojis_en_contenido)\n",
    "    \n",
    "    # Cuenta la frecuencia de cada emoji\n",
    "    conteo_emojis = Counter(todos_emojis)\n",
    "    \n",
    "    # Encuentra los 10 emojis más comunes\n",
    "    top_emojis = conteo_emojis.most_common(10)\n",
    "    \n",
    "    return top_emojis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Enfoque: Memoria en uso optimizada\n",
    " - Descripción: Este código define una función llamada q2_memory que procesa un archivo de texto. Lee cada línea del archivo, interpreta cada línea como un objeto JSON que representa un tweet y cuenta la frecuencia de cada emoji en el contenido de los tweets. Luego, devuelve una lista de los 10 emojis más comunes junto con sus recuentos. El resultado final es una lista de tuplas que contienen el emoji y su frecuencia de aparición en los tweets del archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Inicializa un contador para contar emojis\n",
    "    conteo_emojis = Counter()\n",
    "    \n",
    "    # Abre el archivo en modo lectura\n",
    "    with open(file_path, 'r') as archivo:\n",
    "        # Itera sobre cada línea en el archivo\n",
    "        for linea in archivo:\n",
    "            # Carga cada línea como un objeto JSON\n",
    "            tweet = json.loads(linea)\n",
    "            \n",
    "            # Obtiene el contenido del tweet o una cadena vacía si no hay contenido\n",
    "            contenido = tweet.get('content', '')\n",
    "            \n",
    "            # Extrae los emojis del contenido del tweet y actualiza el contador de emojis\n",
    "            emojis_en_contenido = [entrada['emoji'] for entrada in emoji.emoji_list(contenido)]\n",
    "            conteo_emojis.update(emojis_en_contenido)\n",
    "    \n",
    "    # Encuentra los 10 emojis más comunes\n",
    "    top_emojis = conteo_emojis.most_common(10)\n",
    "    \n",
    "    return top_emojis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos. \n",
    "- Enfoque: Tiempo de ejecucion optimizado\n",
    "- Descripción: Este código define una función llamada q3_time que procesa un archivo. Primero, verifica si existe un archivo Parquet con el mismo nombre que el archivo JSON de entrada. Si existe, lo lee; de lo contrario, lee el archivo JSON, encuentra menciones en el contenido de los tweets, cuenta la frecuencia de cada mención y devuelve una lista de las 10 menciones más frecuentes junto con sus recuentos. El resultado final es una lista de tuplas que contienen el nombre de usuario mencionado y la frecuencia de aparición en los tweets del archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Crea el nombre del archivo Parquet reemplazando la extensión .json por .parquet\n",
    "    archivo_parquet = file_path.replace('.json', '.parquet')\n",
    "    \n",
    "    # Verifica si existe el archivo Parquet\n",
    "    if os.path.exists(archivo_parquet):\n",
    "        # Lee el archivo Parquet si existe\n",
    "        df = pd.read_parquet(archivo_parquet)\n",
    "    else:\n",
    "        # Lee el archivo JSON si el Parquet no existe y lo guarda como Parquet\n",
    "        df = pd.read_json(file_path, lines=True)\n",
    "        df.to_parquet(archivo_parquet, index=False)\n",
    "    \n",
    "    # Encuentra menciones en el contenido de los tweets y crea una nueva columna 'mentions'\n",
    "    df['menciones'] = df['content'].str.findall(r'@(\\w+)')\n",
    "    \n",
    "    # Divide las filas del DataFrame por cada mención, creando múltiples filas duplicadas\n",
    "    df = df.explode('menciones', ignore_index=True)\n",
    "    \n",
    "    # Calcula la frecuencia de menciones y crea un nuevo DataFrame con columnas 'nombre_de_usuario' y 'conteo'\n",
    "    conteo_menciones = df['menciones'].value_counts().reset_index()\n",
    "    conteo_menciones.columns = ['nombre_de_usuario', 'conteo']\n",
    "    \n",
    "    # Obtiene las 10 menciones más frecuentes como un iterable de tuplas sin índice\n",
    "    top_menciones = conteo_menciones.head(10).itertuples(index=False, name=None)\n",
    "    \n",
    "    # Convierte el iterable en una lista de tuplas\n",
    "    return list(top_menciones)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Enfoque: Memoria en uso optimizada\n",
    " - Descripción: Este código define una función llamada q3_memory que procesa un archivo de texto. Lee cada línea del archivo, intenta cargarla como un objeto JSON (capturando excepciones JSONDecodeError para líneas inválidas), busca menciones en el contenido de los tweets y cuenta la frecuencia de cada mención. Luego, devuelve una lista de las 10 menciones más frecuentes junto con sus recuentos. El resultado final es una lista de tuplas que contienen el nombre de usuario mencionado y la frecuencia de aparición en los tweets del archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Inicializa un contador para contar menciones\n",
    "    conteo_menciones = Counter()\n",
    "    \n",
    "    # Abre el archivo en modo lectura\n",
    "    with open(file_path, 'r') as archivo:\n",
    "        # Itera sobre cada línea en el archivo\n",
    "        for linea in archivo:\n",
    "            try:\n",
    "                # Intenta cargar cada línea como un objeto JSON (puede haber excepciones JSONDecodeError)\n",
    "                tweet = json.loads(linea)\n",
    "                \n",
    "                # Obtiene el contenido del tweet o una cadena vacía si no hay contenido\n",
    "                contenido = tweet.get('content', '')\n",
    "                \n",
    "                # Encuentra menciones en el contenido del tweet\n",
    "                menciones = re.findall(r'@(\\w+)', contenido)\n",
    "                \n",
    "                # Actualiza el contador de menciones con las menciones encontradas\n",
    "                conteo_menciones.update(menciones)\n",
    "            except json.JSONDecodeError:\n",
    "                # Captura excepciones JSONDecodeError en caso de líneas inválidas\n",
    "                pass\n",
    "    \n",
    "    # Obtiene las 10 menciones más frecuentes\n",
    "    top_menciones = conteo_menciones.most_common(10)\n",
    "    \n",
    "    return top_menciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_time(\"./farmers-protest-tweets-2021-2-4.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 19), 'Preetm91'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 21), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist')]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_memory(\"./farmers-protest-tweets-2021-2-4.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('🙏', 5049),\n",
       " ('😂', 3072),\n",
       " ('🚜', 2972),\n",
       " ('🌾', 2182),\n",
       " ('🇮🇳', 2086),\n",
       " ('🤣', 1668),\n",
       " ('✊', 1651),\n",
       " ('❤️', 1382),\n",
       " ('🙏🏻', 1317),\n",
       " ('💚', 1040)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_time(\"./farmers-protest-tweets-2021-2-4.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('🙏', 5049),\n",
       " ('😂', 3072),\n",
       " ('🚜', 2972),\n",
       " ('🌾', 2182),\n",
       " ('🇮🇳', 2086),\n",
       " ('🤣', 1668),\n",
       " ('✊', 1651),\n",
       " ('❤️', 1382),\n",
       " ('🙏🏻', 1317),\n",
       " ('💚', 1040)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_memory(\"./farmers-protest-tweets-2021-2-4.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2261),\n",
       " ('Kisanektamorcha', 1836),\n",
       " ('RakeshTikaitBKU', 1639),\n",
       " ('PMOIndia', 1422),\n",
       " ('RahulGandhi', 1125),\n",
       " ('GretaThunberg', 1046),\n",
       " ('RaviSinghKA', 1015),\n",
       " ('rihanna', 972),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 925)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_time(\"./farmers-protest-tweets-2021-2-4.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2261),\n",
       " ('Kisanektamorcha', 1836),\n",
       " ('RakeshTikaitBKU', 1639),\n",
       " ('PMOIndia', 1422),\n",
       " ('RahulGandhi', 1125),\n",
       " ('GretaThunberg', 1046),\n",
       " ('RaviSinghKA', 1015),\n",
       " ('rihanna', 972),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 925)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_memory(\"./farmers-protest-tweets-2021-2-4.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medición y evaluación de las funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "Evaluación de memoria q1_time\n",
      "peak memory: 3458.63 MiB, increment: 189.10 MiB\n",
      "Evaluación de memoria q1_memory\n",
      "peak memory: 3388.33 MiB, increment: 0.41 MiB\n",
      "Tue Oct  3 04:12:28 2023    output.pstats1\n",
      "\n",
      "         3286184 function calls (3285917 primitive calls) in 8.495 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 879 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        3    0.000    0.000    8.495    2.832 C:\\Users\\Juan Hurtado\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3469(run_code)\n",
      "        3    0.000    0.000    8.495    2.832 {built-in method builtins.exec}\n",
      "        1    1.328    1.328    6.709    6.709 C:\\Users\\Juan Hurtado\\AppData\\Local\\Temp\\ipykernel_35976\\2436507414.py:1(q1_memory)\n",
      "   117407    2.362    0.000    2.362    0.000 {built-in method ujson.loads}\n",
      "   117407    0.074    0.000    2.103    0.000 {built-in method strptime}\n",
      "   117407    0.196    0.000    2.029    0.000 c:\\Users\\Juan Hurtado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\_strptime.py:565(_strptime_datetime)\n",
      "   117407    1.007    0.000    1.833    0.000 c:\\Users\\Juan Hurtado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\_strptime.py:309(_strptime)\n",
      "        1    0.096    0.096    1.786    1.786 C:\\Users\\Juan Hurtado\\AppData\\Local\\Temp\\ipykernel_35976\\2783166282.py:1(<module>)\n",
      "        1    0.001    0.001    1.690    1.690 C:\\Users\\Juan Hurtado\\AppData\\Local\\Temp\\ipykernel_35976\\1902760566.py:1(q1_time)\n",
      "        1    0.000    0.000    1.631    1.631 c:\\Users\\Juan Hurtado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parquet.py:447(read_parquet)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x1d3b8668390>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga la extensión memory_profiler para evaluar el uso de memoria en las funciones\n",
    "%load_ext memory_profiler\n",
    "\n",
    "# Evaluar el uso de memoria de la función q1_time\n",
    "print(\"Evaluación de memoria q1_time\")\n",
    "%memit q1_time(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "# Evaluar el uso de memoria de la función q1_memory\n",
    "print(\"Evaluación de memoria q1_memory\")\n",
    "%memit q1_memory(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "# Inicializar el profiler de cProfile para evaluar el rendimiento del código\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "# Llamar a las funciones q1_memory y q1_time para medir el rendimiento\n",
    "q1_memory(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "q1_time(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "# Deshabilitar el profiler cProfile y guardar estadísticas en un archivo\n",
    "profiler.disable()\n",
    "profiler.dump_stats(\"output.pstats1\")\n",
    "\n",
    "# Crear una instancia de Stats de pstats para analizar las estadísticas\n",
    "stats = pstats.Stats(\"output.pstats1\")\n",
    "\n",
    "# Ordenar y mostrar las estadísticas según el tiempo acumulativo (cumulative) de las 10 funciones principales\n",
    "stats.sort_stats(\"cumulative\")\n",
    "stats.print_stats(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "Evaluación de memoria q2_time\n",
      "peak memory: 3505.53 MiB, increment: 89.42 MiB\n",
      "Evaluación de memoria q2_memory\n",
      "peak memory: 3434.79 MiB, increment: 0.06 MiB\n",
      "Tue Oct  3 04:14:17 2023    output.pstats2\n",
      "\n",
      "         138721680 function calls (138721667 primitive calls) in 70.338 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 400 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        3    0.000    0.000   79.898   26.633 C:\\Users\\Juan Hurtado\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3469(run_code)\n",
      "        3    0.000    0.000   79.898   26.633 {built-in method builtins.exec}\n",
      "   234814    0.176    0.000   72.786    0.000 c:\\Users\\Juan Hurtado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\emoji\\core.py:282(emoji_list)\n",
      "   234814   12.642    0.000   72.610    0.000 c:\\Users\\Juan Hurtado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\emoji\\core.py:289(<listcomp>)\n",
      " 34281412   38.001    0.000   56.271    0.000 c:\\Users\\Juan Hurtado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\emoji\\tokenizer.py:158(tokenize)\n",
      "        1    1.462    1.462   42.020   42.020 C:\\Users\\Juan Hurtado\\AppData\\Local\\Temp\\ipykernel_35976\\3002260097.py:1(q2_memory)\n",
      "        1    0.105    0.105   37.878   37.878 C:\\Users\\Juan Hurtado\\AppData\\Local\\Temp\\ipykernel_35976\\1391583387.py:1(<module>)\n",
      "        1    0.146    0.146   37.774   37.774 C:\\Users\\Juan Hurtado\\AppData\\Local\\Temp\\ipykernel_35976\\1170759707.py:1(q2_time)\n",
      " 34046613    5.421    0.000    5.421    0.000 {built-in method __new__ of type object at 0x00007FFDACB58F90}\n",
      "34164325/34164321    3.749    0.000    3.831    0.000 {built-in method builtins.isinstance}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x1d3bb08a7d0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga la extensión memory_profiler para evaluar el uso de memoria en las funciones\n",
    "%load_ext memory_profiler\n",
    "\n",
    "# Evaluar el uso de memoria de la función q2_time\n",
    "print(\"Evaluación de memoria q2_time\")\n",
    "%memit q2_time(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "# Evaluar el uso de memoria de la función q2_memory\n",
    "print(\"Evaluación de memoria q2_memory\")\n",
    "%memit q2_memory(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "# Inicializar el profiler de cProfile para evaluar el rendimiento del código\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "# Llamar a las funciones q2_memory y q2_time para medir el rendimiento\n",
    "q2_memory(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "q2_time(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "# Deshabilitar el profiler cProfile y guardar estadísticas en un archivo\n",
    "profiler.disable()\n",
    "profiler.dump_stats(\"output.pstats2\")\n",
    "\n",
    "# Crear una instancia de Stats de pstats para analizar las estadísticas\n",
    "stats = pstats.Stats(\"output.pstats2\")\n",
    "\n",
    "# Ordenar y mostrar las estadísticas según el tiempo acumulativo (cumulative) de las 10 funciones principales\n",
    "stats.sort_stats(\"cumulative\")\n",
    "stats.print_stats(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "Evaluación de memoria q3_time\n",
      "peak memory: 3612.97 MiB, increment: 158.05 MiB\n",
      "Evaluación de memoria q3_memory\n",
      "peak memory: 3470.02 MiB, increment: 0.03 MiB\n",
      "Tue Oct  3 04:14:31 2023    output.pstats3\n",
      "\n",
      "         1399510 function calls (1399366 primitive calls) in 6.752 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 838 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        3    0.000    0.000    6.767    2.256 C:\\Users\\Juan Hurtado\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3469(run_code)\n",
      "        3    0.000    0.000    6.767    2.256 {built-in method builtins.exec}\n",
      "        1    1.122    1.122    4.697    4.697 C:\\Users\\Juan Hurtado\\AppData\\Local\\Temp\\ipykernel_35976\\1862612398.py:1(q3_memory)\n",
      "   117407    2.235    0.000    2.235    0.000 {built-in method ujson.loads}\n",
      "        1    0.013    0.013    2.055    2.055 C:\\Users\\Juan Hurtado\\AppData\\Local\\Temp\\ipykernel_35976\\1858695508.py:1(q3_time)\n",
      "        1    0.000    0.000    1.637    1.637 c:\\Users\\Juan Hurtado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parquet.py:447(read_parquet)\n",
      "        1    0.002    0.002    1.637    1.637 c:\\Users\\Juan Hurtado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parquet.py:211(read)\n",
      "        1    0.000    0.000    1.235    1.235 {method 'to_pandas' of 'pyarrow.lib._PandasConvertible' objects}\n",
      "        1    0.000    0.000    1.235    1.235 c:\\Users\\Juan Hurtado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\pandas_compat.py:749(table_to_blockmanager)\n",
      "        1    0.000    0.000    1.231    1.231 c:\\Users\\Juan Hurtado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\pandas_compat.py:1115(_table_to_blocks)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x1d3bdf6cdd0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga la extensión memory_profiler para evaluar el uso de memoria en las funciones\n",
    "%load_ext memory_profiler\n",
    "\n",
    "# Evaluar el uso de memoria de la función q3_time\n",
    "print(\"Evaluación de memoria q3_time\")\n",
    "%memit q3_time(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "# Evaluar el uso de memoria de la función q3_memory\n",
    "print(\"Evaluación de memoria q3_memory\")\n",
    "%memit q3_memory(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "# Inicializar el profiler de cProfile para evaluar el rendimiento del código\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "# Llamar a las funciones q3_memory y q3_time para medir el rendimiento\n",
    "q3_memory(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "q3_time(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "# Deshabilitar el profiler cProfile y guardar estadísticas en un archivo\n",
    "profiler.disable()\n",
    "profiler.dump_stats(\"output.pstats3\")\n",
    "\n",
    "# Crear una instancia de Stats de pstats para analizar las estadísticas\n",
    "stats = pstats.Stats(\"output.pstats3\")\n",
    "\n",
    "# Ordenar y mostrar las estadísticas según el tiempo acumulativo (cumulative) de las 10 funciones principales\n",
    "stats.sort_stats(\"cumulative\")\n",
    "stats.print_stats(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
