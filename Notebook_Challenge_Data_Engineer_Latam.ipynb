{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Data Engineer LATAM - Juan Felipe Hurtado\n",
    "\n",
    "- El archivo json se tiene en el directorio raiz de este archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importaciones globales del reto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ujson as json\n",
    "import emoji\n",
    "import re\n",
    "import cProfile\n",
    "import pstats\n",
    "from memory_profiler import profile\n",
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Las top 10 fechas donde hay m√°s tweets. \n",
    "Mencionar el usuario (username) que m√°s publicaciones tiene por cada uno de esos d√≠as.\n",
    "- Enfoque: Tiempo de ejecucion optimizado.\n",
    "\n",
    "- Descripci√≥n:\n",
    "Este c√≥digo define una funci√≥n llamada q1_time que procesa un archivo. Si existe un archivo Parquet m√°s reciente que el archivo original, lo lee; de lo contrario, lee el archivo JSON, realiza manipulaciones de datos y lo guarda como Parquet. Luego, identifica las 10 fechas con m√°s apariciones en el archivo original y, para cada una de ellas, encuentra el nombre de usuario con m√°s apariciones en esa fecha. El resultado final es una lista de tuplas que contienen la fecha y el nombre de usuario correspondiente para las 10 fechas principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_time(archivo_json: str) -> List[Tuple[datetime.date, str]]:\n",
    "    # Separar el nombre del archivo y su extensi√≥n\n",
    "    nombre_archivo, _ = os.path.splitext(archivo_json)\n",
    "    archivo_parquet = f\"{nombre_archivo}.parquet\"\n",
    "    \n",
    "    # Verificar si existe un archivo parquet m√°s reciente que el JSON\n",
    "    if os.path.exists(archivo_parquet) and os.path.getmtime(archivo_parquet) >= os.path.getmtime(archivo_json):\n",
    "        # Si existe y es m√°s reciente, cargar datos desde el archivo parquet\n",
    "        df = pd.read_parquet(archivo_parquet)\n",
    "    else:\n",
    "        # Si no existe un archivo parquet o es m√°s antiguo, cargar datos desde el JSON\n",
    "        df = pd.read_json(archivo_json, lines=True)\n",
    "        # Optimizar la conversi√≥n de fecha y extracci√≥n de nombre de usuario\n",
    "        df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "        df['username'] = df['user'].apply(lambda x: x.get('username'))\n",
    "        df.drop(columns=['user'], inplace=True)\n",
    "        # Guardar los datos procesados en formato parquet\n",
    "        df.to_parquet(archivo_parquet, index=False)\n",
    "\n",
    "    # Obtener el usuario con m√°s tweets para cada fecha de manera eficiente\n",
    "    top_users_df = df.groupby(['date', 'username']).size().reset_index(name='count')\n",
    "    top_users_df = top_users_df.loc[top_users_df.groupby('date')['count'].idxmax()]\n",
    "    \n",
    "    # Encontrar las 10 fechas con m√°s tweets y los usuarios correspondientes de manera eficiente\n",
    "    top_dates_df = df['date'].value_counts().nlargest(10).reset_index()\n",
    "    result = [(fecha, top_users_df[top_users_df['date'] == fecha]['username'].values[0]) for fecha in top_dates_df['index']]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Enfoque: Memoria en uso optimizada\n",
    " - Descripci√≥n: Este c√≥digo define una funci√≥n llamada q1_memory que procesa un archivo de texto. Lee cada l√≠nea del archivo, interpreta cada l√≠nea como un objeto JSON que representa un tweet, y realiza un seguimiento de la fecha y el nombre de usuario m√°s frecuentes para cada fecha. Luego, encuentra las 10 fechas con mayor n√∫mero de usuarios √∫nicos y devuelve una lista de tuplas que contienen la fecha y el nombre de usuario m√°s frecuente para cada una de esas fechas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    # Crear un diccionario anidado para contar usuarios por fecha\n",
    "    usuarios_por_fecha = defaultdict(lambda: defaultdict(int))\n",
    "    # Abrir el archivo en modo lectura\n",
    "    with open(file_path, \"r\") as archivo:\n",
    "        # Iterar sobre cada l√≠nea en el archivo\n",
    "        for linea in archivo:\n",
    "            # Cargar cada l√≠nea como un objeto JSON\n",
    "            tweet = json.loads(linea)\n",
    "            # Extraer la fecha del tweet y convertirla en un objeto de fecha\n",
    "            fecha_tweet_str = tweet['date'].split(\"T\")[0]\n",
    "            fecha_tweet = datetime.strptime(fecha_tweet_str, '%Y-%m-%d').date()\n",
    "            # Obtener el nombre de usuario del tweet\n",
    "            nombre_usuario = tweet['user']['username']\n",
    "            # Actualizar el contador de usuarios por fecha\n",
    "            usuarios_por_fecha[fecha_tweet][nombre_usuario] += 1\n",
    "    # Inicializar una lista vac√≠a para almacenar las fechas y usuarios principales\n",
    "    fechas_usuarios_principales = []\n",
    "    # Iterar a trav√©s de las fechas y sus recuentos de usuarios\n",
    "    for fecha, recuentos_usuarios in usuarios_por_fecha.items():\n",
    "        # Encontrar el usuario con el recuento m√°ximo para cada fecha\n",
    "        usuario_principal = max(recuentos_usuarios, key=recuentos_usuarios.get)\n",
    "        # Agregar la fecha y el usuario principal a la lista\n",
    "        fechas_usuarios_principales.append((fecha, usuario_principal))\n",
    "    # Ordenar la lista por recuento de usuarios en orden descendente y tomar las 10 primeras entradas\n",
    "    resultado = sorted(fechas_usuarios_principales, key=lambda x: usuarios_por_fecha[x[0]][x[1]], reverse=True)[:10]\n",
    "\n",
    "    return resultado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Los top 10 emojis m√°s usados con su respectivo conteo.\n",
    "- Enfoque: Tiempo de ejecucion optimizado\n",
    "- Descripci√≥n: Este c√≥digo define una funci√≥n llamada q2_time que procesa un archivo. Primero, verifica si existe un archivo Parquet con el mismo nombre que el archivo JSON de entrada. Si existe, lo lee; de lo contrario, lee el archivo JSON, extrae los emojis de los contenidos de los tweets, cuenta la frecuencia de cada emoji y devuelve una lista de los 10 emojis m√°s comunes junto con sus recuentos. El resultado final es una lista de tuplas que contienen el emoji y su frecuencia de aparici√≥n en los tweets del archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Crea el nombre del archivo Parquet reemplazando la extensi√≥n .json por .parquet\n",
    "    archivo_parquet = file_path.replace('.json', '.parquet')\n",
    "    \n",
    "    # Verifica si existe el archivo Parquet\n",
    "    if os.path.exists(archivo_parquet):\n",
    "        # Lee el archivo Parquet si existe\n",
    "        df = pd.read_parquet(archivo_parquet)\n",
    "    else:\n",
    "        # Lee el archivo JSON si el Parquet no existe y lo guarda como Parquet\n",
    "        df = pd.read_json(file_path, lines=True)\n",
    "        df.to_parquet(archivo_parquet, index=False)\n",
    "    \n",
    "    # Inicializa una lista vac√≠a para almacenar todos los emojis en el contenido de los tweets\n",
    "    todos_emojis = []\n",
    "    \n",
    "    # Itera a trav√©s de la columna 'content' del DataFrame\n",
    "    for contenido in df['content']:\n",
    "        # Extrae los emojis de cada contenido y los agrega a la lista de todos los emojis\n",
    "        emojis_en_contenido = [entrada['emoji'] for entrada in emoji.emoji_list(contenido)]\n",
    "        todos_emojis.extend(emojis_en_contenido)\n",
    "    \n",
    "    # Cuenta la frecuencia de cada emoji\n",
    "    conteo_emojis = Counter(todos_emojis)\n",
    "    \n",
    "    # Encuentra los 10 emojis m√°s comunes\n",
    "    top_emojis = conteo_emojis.most_common(10)\n",
    "    \n",
    "    return top_emojis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Enfoque: Memoria en uso optimizada\n",
    " - Descripci√≥n: Este c√≥digo define una funci√≥n llamada q2_memory que procesa un archivo de texto. Lee cada l√≠nea del archivo, interpreta cada l√≠nea como un objeto JSON que representa un tweet y cuenta la frecuencia de cada emoji en el contenido de los tweets. Luego, devuelve una lista de los 10 emojis m√°s comunes junto con sus recuentos. El resultado final es una lista de tuplas que contienen el emoji y su frecuencia de aparici√≥n en los tweets del archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Inicializa un contador para contar emojis\n",
    "    conteo_emojis = Counter()\n",
    "    \n",
    "    # Abre el archivo en modo lectura\n",
    "    with open(file_path, 'r') as archivo:\n",
    "        # Itera sobre cada l√≠nea en el archivo\n",
    "        for linea in archivo:\n",
    "            # Carga cada l√≠nea como un objeto JSON\n",
    "            tweet = json.loads(linea)\n",
    "            \n",
    "            # Obtiene el contenido del tweet o una cadena vac√≠a si no hay contenido\n",
    "            contenido = tweet.get('content', '')\n",
    "            \n",
    "            # Extrae los emojis del contenido del tweet y actualiza el contador de emojis\n",
    "            emojis_en_contenido = [entrada['emoji'] for entrada in emoji.emoji_list(contenido)]\n",
    "            conteo_emojis.update(emojis_en_contenido)\n",
    "    \n",
    "    # Encuentra los 10 emojis m√°s comunes\n",
    "    top_emojis = conteo_emojis.most_common(10)\n",
    "    \n",
    "    return top_emojis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. El top 10 hist√≥rico de usuarios (username) m√°s influyentes en funci√≥n del conteo de las menciones (@) que registra cada uno de ellos. \n",
    "- Enfoque: Tiempo de ejecucion optimizado\n",
    "- Descripci√≥n: Este c√≥digo define una funci√≥n llamada q3_time que procesa un archivo. Primero, verifica si existe un archivo Parquet con el mismo nombre que el archivo JSON de entrada. Si existe, lo lee; de lo contrario, lee el archivo JSON, encuentra menciones en el contenido de los tweets, cuenta la frecuencia de cada menci√≥n y devuelve una lista de las 10 menciones m√°s frecuentes junto con sus recuentos. El resultado final es una lista de tuplas que contienen el nombre de usuario mencionado y la frecuencia de aparici√≥n en los tweets del archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Crea el nombre del archivo Parquet reemplazando la extensi√≥n .json por .parquet\n",
    "    archivo_parquet = file_path.replace('.json', '.parquet')\n",
    "    \n",
    "    # Verifica si existe el archivo Parquet\n",
    "    if os.path.exists(archivo_parquet):\n",
    "        # Lee el archivo Parquet si existe\n",
    "        df = pd.read_parquet(archivo_parquet)\n",
    "    else:\n",
    "        # Lee el archivo JSON si el Parquet no existe y lo guarda como Parquet\n",
    "        df = pd.read_json(file_path, lines=True)\n",
    "        df.to_parquet(archivo_parquet, index=False)\n",
    "    \n",
    "    # Encuentra menciones en el contenido de los tweets y crea una nueva columna 'mentions'\n",
    "    df['menciones'] = df['content'].str.findall(r'@(\\w+)')\n",
    "    \n",
    "    # Divide las filas del DataFrame por cada menci√≥n, creando m√∫ltiples filas duplicadas\n",
    "    df = df.explode('menciones', ignore_index=True)\n",
    "    \n",
    "    # Calcula la frecuencia de menciones y crea un nuevo DataFrame con columnas 'nombre_de_usuario' y 'conteo'\n",
    "    conteo_menciones = df['menciones'].value_counts().reset_index()\n",
    "    conteo_menciones.columns = ['nombre_de_usuario', 'conteo']\n",
    "    \n",
    "    # Obtiene las 10 menciones m√°s frecuentes como un iterable de tuplas sin √≠ndice\n",
    "    top_menciones = conteo_menciones.head(10).itertuples(index=False, name=None)\n",
    "    \n",
    "    # Convierte el iterable en una lista de tuplas\n",
    "    return list(top_menciones)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Enfoque: Memoria en uso optimizada\n",
    " - Descripci√≥n: Este c√≥digo define una funci√≥n llamada q3_memory que procesa un archivo de texto. Lee cada l√≠nea del archivo, intenta cargarla como un objeto JSON (capturando excepciones JSONDecodeError para l√≠neas inv√°lidas), busca menciones en el contenido de los tweets y cuenta la frecuencia de cada menci√≥n. Luego, devuelve una lista de las 10 menciones m√°s frecuentes junto con sus recuentos. El resultado final es una lista de tuplas que contienen el nombre de usuario mencionado y la frecuencia de aparici√≥n en los tweets del archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Inicializa un contador para contar menciones\n",
    "    conteo_menciones = Counter()\n",
    "    \n",
    "    # Abre el archivo en modo lectura\n",
    "    with open(file_path, 'r') as archivo:\n",
    "        # Itera sobre cada l√≠nea en el archivo\n",
    "        for linea in archivo:\n",
    "            try:\n",
    "                # Intenta cargar cada l√≠nea como un objeto JSON (puede haber excepciones JSONDecodeError)\n",
    "                tweet = json.loads(linea)\n",
    "                \n",
    "                # Obtiene el contenido del tweet o una cadena vac√≠a si no hay contenido\n",
    "                contenido = tweet.get('content', '')\n",
    "                \n",
    "                # Encuentra menciones en el contenido del tweet\n",
    "                menciones = re.findall(r'@(\\w+)', contenido)\n",
    "                \n",
    "                # Actualiza el contador de menciones con las menciones encontradas\n",
    "                conteo_menciones.update(menciones)\n",
    "            except json.JSONDecodeError:\n",
    "                # Captura excepciones JSONDecodeError en caso de l√≠neas inv√°lidas\n",
    "                pass\n",
    "    \n",
    "    # Obtiene las 10 menciones m√°s frecuentes\n",
    "    top_menciones = conteo_menciones.most_common(10)\n",
    "    \n",
    "    return top_menciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_time(\"./farmers-protest-tweets-2021-2-4.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 19), 'Preetm91'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 21), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist')]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_memory(\"./farmers-protest-tweets-2021-2-4.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('üôè', 5049),\n",
       " ('üòÇ', 3072),\n",
       " ('üöú', 2972),\n",
       " ('üåæ', 2182),\n",
       " ('üáÆüá≥', 2086),\n",
       " ('ü§£', 1668),\n",
       " ('‚úä', 1651),\n",
       " ('‚ù§Ô∏è', 1382),\n",
       " ('üôèüèª', 1317),\n",
       " ('üíö', 1040)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_time(\"./farmers-protest-tweets-2021-2-4.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('üôè', 5049),\n",
       " ('üòÇ', 3072),\n",
       " ('üöú', 2972),\n",
       " ('üåæ', 2182),\n",
       " ('üáÆüá≥', 2086),\n",
       " ('ü§£', 1668),\n",
       " ('‚úä', 1651),\n",
       " ('‚ù§Ô∏è', 1382),\n",
       " ('üôèüèª', 1317),\n",
       " ('üíö', 1040)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_memory(\"./farmers-protest-tweets-2021-2-4.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2261),\n",
       " ('Kisanektamorcha', 1836),\n",
       " ('RakeshTikaitBKU', 1639),\n",
       " ('PMOIndia', 1422),\n",
       " ('RahulGandhi', 1125),\n",
       " ('GretaThunberg', 1046),\n",
       " ('RaviSinghKA', 1015),\n",
       " ('rihanna', 972),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 925)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_time(\"./farmers-protest-tweets-2021-2-4.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2261),\n",
       " ('Kisanektamorcha', 1836),\n",
       " ('RakeshTikaitBKU', 1639),\n",
       " ('PMOIndia', 1422),\n",
       " ('RahulGandhi', 1125),\n",
       " ('GretaThunberg', 1046),\n",
       " ('RaviSinghKA', 1015),\n",
       " ('rihanna', 972),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 925)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_memory(\"./farmers-protest-tweets-2021-2-4.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medici√≥n y evaluaci√≥n de las funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "Evaluaci√≥n de memoria q1_time\n",
      "peak memory: 3458.63 MiB, increment: 189.10 MiB\n",
      "Evaluaci√≥n de memoria q1_memory\n",
      "peak memory: 3388.33 MiB, increment: 0.41 MiB\n",
      "Tue Oct  3 04:12:28 2023    output.pstats1\n",
      "\n",
      "         3286184 function calls (3285917 primitive calls) in 8.495 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 879 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        3    0.000    0.000    8.495    2.832 C:\\Users\\Juan Hurtado\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3469(run_code)\n",
      "        3    0.000    0.000    8.495    2.832 {built-in method builtins.exec}\n",
      "        1    1.328    1.328    6.709    6.709 C:\\Users\\Juan Hurtado\\AppData\\Local\\Temp\\ipykernel_35976\\2436507414.py:1(q1_memory)\n",
      "   117407    2.362    0.000    2.362    0.000 {built-in method ujson.loads}\n",
      "   117407    0.074    0.000    2.103    0.000 {built-in method strptime}\n",
      "   117407    0.196    0.000    2.029    0.000 c:\\Users\\Juan Hurtado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\_strptime.py:565(_strptime_datetime)\n",
      "   117407    1.007    0.000    1.833    0.000 c:\\Users\\Juan Hurtado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\_strptime.py:309(_strptime)\n",
      "        1    0.096    0.096    1.786    1.786 C:\\Users\\Juan Hurtado\\AppData\\Local\\Temp\\ipykernel_35976\\2783166282.py:1(<module>)\n",
      "        1    0.001    0.001    1.690    1.690 C:\\Users\\Juan Hurtado\\AppData\\Local\\Temp\\ipykernel_35976\\1902760566.py:1(q1_time)\n",
      "        1    0.000    0.000    1.631    1.631 c:\\Users\\Juan Hurtado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parquet.py:447(read_parquet)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x1d3b8668390>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga la extensi√≥n memory_profiler para evaluar el uso de memoria en las funciones\n",
    "%load_ext memory_profiler\n",
    "\n",
    "# Evaluar el uso de memoria de la funci√≥n q1_time\n",
    "print(\"Evaluaci√≥n de memoria q1_time\")\n",
    "%memit q1_time(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "# Evaluar el uso de memoria de la funci√≥n q1_memory\n",
    "print(\"Evaluaci√≥n de memoria q1_memory\")\n",
    "%memit q1_memory(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "# Inicializar el profiler de cProfile para evaluar el rendimiento del c√≥digo\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "# Llamar a las funciones q1_memory y q1_time para medir el rendimiento\n",
    "q1_memory(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "q1_time(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "# Deshabilitar el profiler cProfile y guardar estad√≠sticas en un archivo\n",
    "profiler.disable()\n",
    "profiler.dump_stats(\"output.pstats1\")\n",
    "\n",
    "# Crear una instancia de Stats de pstats para analizar las estad√≠sticas\n",
    "stats = pstats.Stats(\"output.pstats1\")\n",
    "\n",
    "# Ordenar y mostrar las estad√≠sticas seg√∫n el tiempo acumulativo (cumulative) de las 10 funciones principales\n",
    "stats.sort_stats(\"cumulative\")\n",
    "stats.print_stats(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "Evaluaci√≥n de memoria q2_time\n",
      "peak memory: 3505.53 MiB, increment: 89.42 MiB\n",
      "Evaluaci√≥n de memoria q2_memory\n",
      "peak memory: 3434.79 MiB, increment: 0.06 MiB\n",
      "Tue Oct  3 04:14:17 2023    output.pstats2\n",
      "\n",
      "         138721680 function calls (138721667 primitive calls) in 70.338 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 400 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        3    0.000    0.000   79.898   26.633 C:\\Users\\Juan Hurtado\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3469(run_code)\n",
      "        3    0.000    0.000   79.898   26.633 {built-in method builtins.exec}\n",
      "   234814    0.176    0.000   72.786    0.000 c:\\Users\\Juan Hurtado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\emoji\\core.py:282(emoji_list)\n",
      "   234814   12.642    0.000   72.610    0.000 c:\\Users\\Juan Hurtado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\emoji\\core.py:289(<listcomp>)\n",
      " 34281412   38.001    0.000   56.271    0.000 c:\\Users\\Juan Hurtado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\emoji\\tokenizer.py:158(tokenize)\n",
      "        1    1.462    1.462   42.020   42.020 C:\\Users\\Juan Hurtado\\AppData\\Local\\Temp\\ipykernel_35976\\3002260097.py:1(q2_memory)\n",
      "        1    0.105    0.105   37.878   37.878 C:\\Users\\Juan Hurtado\\AppData\\Local\\Temp\\ipykernel_35976\\1391583387.py:1(<module>)\n",
      "        1    0.146    0.146   37.774   37.774 C:\\Users\\Juan Hurtado\\AppData\\Local\\Temp\\ipykernel_35976\\1170759707.py:1(q2_time)\n",
      " 34046613    5.421    0.000    5.421    0.000 {built-in method __new__ of type object at 0x00007FFDACB58F90}\n",
      "34164325/34164321    3.749    0.000    3.831    0.000 {built-in method builtins.isinstance}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x1d3bb08a7d0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga la extensi√≥n memory_profiler para evaluar el uso de memoria en las funciones\n",
    "%load_ext memory_profiler\n",
    "\n",
    "# Evaluar el uso de memoria de la funci√≥n q2_time\n",
    "print(\"Evaluaci√≥n de memoria q2_time\")\n",
    "%memit q2_time(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "# Evaluar el uso de memoria de la funci√≥n q2_memory\n",
    "print(\"Evaluaci√≥n de memoria q2_memory\")\n",
    "%memit q2_memory(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "# Inicializar el profiler de cProfile para evaluar el rendimiento del c√≥digo\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "# Llamar a las funciones q2_memory y q2_time para medir el rendimiento\n",
    "q2_memory(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "q2_time(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "# Deshabilitar el profiler cProfile y guardar estad√≠sticas en un archivo\n",
    "profiler.disable()\n",
    "profiler.dump_stats(\"output.pstats2\")\n",
    "\n",
    "# Crear una instancia de Stats de pstats para analizar las estad√≠sticas\n",
    "stats = pstats.Stats(\"output.pstats2\")\n",
    "\n",
    "# Ordenar y mostrar las estad√≠sticas seg√∫n el tiempo acumulativo (cumulative) de las 10 funciones principales\n",
    "stats.sort_stats(\"cumulative\")\n",
    "stats.print_stats(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n",
      "Evaluaci√≥n de memoria q3_time\n",
      "peak memory: 3612.97 MiB, increment: 158.05 MiB\n",
      "Evaluaci√≥n de memoria q3_memory\n",
      "peak memory: 3470.02 MiB, increment: 0.03 MiB\n",
      "Tue Oct  3 04:14:31 2023    output.pstats3\n",
      "\n",
      "         1399510 function calls (1399366 primitive calls) in 6.752 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 838 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        3    0.000    0.000    6.767    2.256 C:\\Users\\Juan Hurtado\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3469(run_code)\n",
      "        3    0.000    0.000    6.767    2.256 {built-in method builtins.exec}\n",
      "        1    1.122    1.122    4.697    4.697 C:\\Users\\Juan Hurtado\\AppData\\Local\\Temp\\ipykernel_35976\\1862612398.py:1(q3_memory)\n",
      "   117407    2.235    0.000    2.235    0.000 {built-in method ujson.loads}\n",
      "        1    0.013    0.013    2.055    2.055 C:\\Users\\Juan Hurtado\\AppData\\Local\\Temp\\ipykernel_35976\\1858695508.py:1(q3_time)\n",
      "        1    0.000    0.000    1.637    1.637 c:\\Users\\Juan Hurtado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parquet.py:447(read_parquet)\n",
      "        1    0.002    0.002    1.637    1.637 c:\\Users\\Juan Hurtado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parquet.py:211(read)\n",
      "        1    0.000    0.000    1.235    1.235 {method 'to_pandas' of 'pyarrow.lib._PandasConvertible' objects}\n",
      "        1    0.000    0.000    1.235    1.235 c:\\Users\\Juan Hurtado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\pandas_compat.py:749(table_to_blockmanager)\n",
      "        1    0.000    0.000    1.231    1.231 c:\\Users\\Juan Hurtado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\pandas_compat.py:1115(_table_to_blocks)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x1d3bdf6cdd0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga la extensi√≥n memory_profiler para evaluar el uso de memoria en las funciones\n",
    "%load_ext memory_profiler\n",
    "\n",
    "# Evaluar el uso de memoria de la funci√≥n q3_time\n",
    "print(\"Evaluaci√≥n de memoria q3_time\")\n",
    "%memit q3_time(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "# Evaluar el uso de memoria de la funci√≥n q3_memory\n",
    "print(\"Evaluaci√≥n de memoria q3_memory\")\n",
    "%memit q3_memory(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "# Inicializar el profiler de cProfile para evaluar el rendimiento del c√≥digo\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "# Llamar a las funciones q3_memory y q3_time para medir el rendimiento\n",
    "q3_memory(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "q3_time(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "# Deshabilitar el profiler cProfile y guardar estad√≠sticas en un archivo\n",
    "profiler.disable()\n",
    "profiler.dump_stats(\"output.pstats3\")\n",
    "\n",
    "# Crear una instancia de Stats de pstats para analizar las estad√≠sticas\n",
    "stats = pstats.Stats(\"output.pstats3\")\n",
    "\n",
    "# Ordenar y mostrar las estad√≠sticas seg√∫n el tiempo acumulativo (cumulative) de las 10 funciones principales\n",
    "stats.sort_stats(\"cumulative\")\n",
    "stats.print_stats(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
